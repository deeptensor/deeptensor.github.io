<!DOCTYPE html> <html lang="en">  <head>   <meta http-equiv="content-type"     content="text/html; charset=utf-8" />     <meta name="viewport"       content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />   <meta name="keywords"     content="Tensor networks" />   <meta name="description"     content="Laboratory tensor networks" />     <title>Neural networks</title>     <link rel="stylesheet" type="text/css" href="style.css" />      <style type="text/css">          .macro_nav956140 {             width: 100%;         }         .macro_nav956140 ul {             margin: 0;             padding: 0;             width: 100%;             display: flex;             flex-flow: row wrap;             justify-content: space-around;             background: #6B7E51;         }         .macro_nav956140 ul li a {             display: inline-block;             margin: 0;             padding: 1.0rem;             text-decoration: none;             color: white;         }         .macro_nav956140 ul li a:hover {             text-decoration: underline;             background-color: #003A56;         }         .macro_nav956140 ul li a.link_active {             cursor: default;         }         .macro_nav956140 ul li a.link_active,         .macro_nav956140 ul li a.link_active_parent {             text-decoration: underline;             background-color: #6B7E51;             color: #003A56;         }       @media all and (max-width: 1000px) {         .macro_nav956140 ul li a {             padding: 0.5rem;             font-size: 0.6rem;         }     }  @media all and (max-width: 530px) {         .macro_nav956140 ul {             flex-flow: column wrap;             align-items: stretch;             padding: 0;         }         .macro_nav956140 ul li {             display: flex;             justify-content: space-around;             padding: 0;             text-align: center;              /*border-left: 1px solid deepskyblue;             border-right: 1px solid deepskyblue;*/             border-top: 1px solid rgba(255,255,255,0.3);              border-bottom: 1px solid rgba(0,0,0,0.1);         }         .macro_nav956140 ul li:last-of-type {             /*border-bottom: none;*/         }         .macro_nav956140 ul li a {               padding: 3px;             width: 100%;         }         .macro_nav956140 ul li:last-of-type a {               padding-bottom: 6px;         }         .macro_nav956140 ul li a.link_active,         .macro_nav956140 ul li a.link_active_parent {             text-decoration: none;             color: rgb(201, 201, 201);             background-color: #003A56;         }     }          .macro_navsub693377 {             /*position: absolute;             right: 0px;             top: 100%;*/             position: fixed;             right: 10px;             top: 30%;             z-index: 100;                  }         .macro_navsub693377 ul {             margin: 1.0rem 0 2.0rem 0;             display: flex;             flex-flow: column nowrap;             justify-content: flex-start;             background: #003A56;             background: linear-gradient(0deg, rgb(0, 105, 152), #003A56);          }         .macro_navsub693377.active ul {             width: auto;         }          .macro_navsub693377 ul li a {             display: none;             padding: 0.9rem 1.5rem;             cursor: pointer;             -webkit-transition: all 0.25s ease;             -moz-transition: all 0.25s ease;             color: white;             border-left: 5px hidden #003A56;         }         .macro_navsub693377.active ul li a, .macro_navsub693377.active ul li a.link_active {             display: block;             cursor: pointer;         }         .macro_navsub693377.active ul li a:hover {             background-color: #256f6f;             color: #003A56;         }         .macro_navsub693377 ul li a.link_active,         .macro_navsub693377.active ul li a.link_active:hover {             background-color: rgb(201, 201, 201);             color: #003A56;                    box-shadow: 3px 3px 5px 6px #003A56;             cursor: default;             text-decoration: none;         }          .macro_navsub693377 button {             /*position: absolute;             top: calc(50% - 50px);*/             margin-left: -30px;             width: 30px;             height: 50px;             background-color: #38a6a6;             color: #fff;             border: none;             line-height: 30px;             vertical-align: middle;             outline: none;             cursor: pointer;             border-top-left-radius: 10px;             border-bottom-left-radius: 10px;             -webkit-transition: all 0.5s ease;             -moz-transition: all 0.5s ease;             transition: all 0.5s ease;         }         .macro_navsub693377 button:hover {             margin-left: -50px;             width: 50px;         }       @media only screen and (max-width: 500px) {         .macro_navsub693377 button {             margin-left: -15px;             width: 15px;         }         .macro_navsub693377 button:hover {             margin-left: -20px;             width: 20px;         }       }          .macro_navsub693377.active button {             background-color: #256f6f;         }          .macro_navsub693377 button span {             display: block;             -webkit-transition: all 2.0s ease;             -moz-transition: all 2.0s ease;             transition: all 2.0s ease;         }         .macro_navsub693377.active button span {             -webkit-transform: rotate(180deg);             -moz-transform: rotate(180deg);             transform: rotate(180deg);         }        header.root {   position: relative;   display: flex;   flex-flow: row wrap;   justify-content: space-between;   align-items: flex-start;   border-top-right-radius: 0.8rem;   background-color: #003A56;  }  header.root a.logo {   flex: 0 1 auto;   margin-left: -9px;  }  header.root p.logo {   flex: 10 1;   padding-top: 0.2rem;   align-self: center;   font-family: 'Russo One', sans-serif;   font-size: 1.5rem;   color: rgb(201, 201, 201);   padding-left: 1.0rem;  }  header.root a.langbox {   flex: 0 1 auto;   background-image: url("static//pictures/icons/rus.gif" );   background-position: left center;   background-repeat: no-repeat;   background-size: auto 1.0rem;   padding: 0.5rem 0.5rem 0.5rem 2.0rem;   margin-left: 0.8rem;   font-size: 1.0rem;   text-decoration: none;   border-radius: 0.8rem;   border: 0.2rem hidden rgb(201, 201, 201);   color: white;  }  header.root a.langbox:hover {   border-style: solid;   color: #BA0000;   box-shadow: 3px 3px 5px 6px rgb(201, 201, 201);   box-shadow: 0.2rem 0.2rem 0.37rem 0.3rem rgb(201, 201, 201);   }   header.root div.header_nav_conn {   display: none;   width: 100%;   height: 10px;   background: #003A56;   background: linear-gradient(0deg, #6B7E51, #003A56);   }   @media all and (max-width: 1080px) {   #p_logo {    font-size: 1.2rem;   } }  @media all and (max-width: 930px) {   #p_logo {    font-size: 1.0rem;   }   header.root div.header_nav_conn {    display: block;   } }  @media all and (max-width: 820px) {   #p_logo {    font-size: 1.0rem;   }   header.root a.logo {     margin-left: -5px;    }   header.root a.logo img {    width: calc(0.7*161px);    height: auto;   } }  @media all and (max-width: 770px) {   #p_logo {    font-size: 0.8rem;   }   header.root a.logo {     margin-left: -3px;    }   header.root a.logo img {    width: calc(0.5*161px);    height: auto;   } }  @media all and (max-width: 700px) {   #p_logo {    font-size: 0.7rem;   }   header.root a.logo {     margin-left: -3px;    }   header.root a.logo img {    width: calc(0.4*161px);    height: auto;   } }  @media all and (max-width: 500px) {   #p_logo {    font-size: 0.65rem;   }   header.root a.logo {     margin-left: -2px;    }   header.root a.logo img {    width: calc(0.25*161px);    height: auto;   } }  @media all and (max-width: 400px) {  #p_logo {   font-size: 0.6rem;   padding-left: 0.5rem;  }  header.root a.logo {    margin-left: -2px;   }  header.root a.logo img {   width: calc(0.2*161px);   height: auto;  }  header.root a.langbox {   background-size: auto 0.4rem;   padding: 0.5rem 0.5rem 0.5rem 0.9rem;   margin-left: 0.4rem;   font-size: 0.6rem;  } }    #content_main p {    margin-top: 0.5rem;    margin-bottom: 0.5rem;    padding-right: 50px;   }   #content_main ol li p:first-of-type {    margin-top: 1.0rem;   }      main.root {    flex-grow: 1;    display: flex;    flex-flow: row wrap-reverse;    justify-content: space-between;    background-color: white;   }   #content_main {    padding: 1.0rem;    margin: 0;    flex: 1 1 330px;   }     footer.root {   background-image: url("static//pictures/background/blue_net2.jpg");   background-position: left bottom;   background-repeat: no-repeat;   background-size: 100% 100%;  }  footer.root, footer.root figure.footer_links_imgs {   display: flex;   flex-flow: row wrap;   justify-content: space-between;   align-items: center;  }  footer.root > * {   flex: 1 0 auto;  }  footer.root .footer_info {   flex: 1000 0 10.0rem;     padding: 0.9rem;   text-align: left;   font-size: 0.9rem;   color: rgb(201, 201, 201);  }  footer.root .footer_links_imgs img {   height: 3.0rem;   width: auto;  }  footer.root .footer_links_imgs img:first-of-type {   padding-right: 1.5rem;  }  @media only screen and (max-width: 400px) {   footer.root .footer_info {    max-width: 250px;   }   footer.root .footer_links_imgs img {    height: 2.0rem;   }     }     html,body,div,dl,dt,dd,ul,ol,li,h1,h2,h3,h4,h5,h6,pre,code,form,fieldset,legend,input,button,label,textarea,select,p,blockquote,th,td,header,footer,section,ul,li,img,figure {     margin: 0;    padding: 0;    border: 0;  }  .nopadding { padding: 0; }   .pad_left_1x { padding-left: 1.5rem;}   .pad_left_2x { padding-left: 3.0rem; }   .pad_top_1x { padding-top: 1.5rem; }   .pad_top_2x { padding-top: 3.0rem; }   .nomargin { margin: 0; }    @media only screen and (max-width: 400px) {     .pad_left_1x { padding-left: 0.5rem;}     .pad_left_2x { padding-left: 1.0rem; }     .pad_top_1x { padding-top: 0.5rem; }     .pad_top_2x { padding-top: 1.0rem; }   }   html {   min-height: 100%;   display: flex;   flex-flow: column nowrap;  }   body {   padding: 0 10px;   flex: 1 1 auto;   display: flex;   flex-flow: column nowrap;  }   .root {   margin: 0 auto;   width: 100%;   min-width:  300px;   max-width: 1400px;   box-sizing: border-box;  }    img { padding: 0; }   </style>     <link rel="icon" href="static//pictures/logo/logo.png">     <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>  </head>  <body>   <header class="root">  <a class="logo" href="index.html">   <img class="logo nopadding"      src="static//pictures/logo/logo.png"     alt="Logo:  Tensor networks and deep learning for applications in data mining"     width="161px" height="122px">  </a>  <p id="p_logo" class="logo">    Tensor networks and deep learning<br> for applications in data mining  </p>   <a class="langbox" href="rus/neural_network.html">   ru  </a>   <div class="header_nav_conn"></div>                      <div class="macro_nav956140">         <ul>                              <li>                     <a href="index.html" class="link_nav                                                                        ">                         Home                     </a>                 </li>                              <li>                     <a href="team.html" class="link_nav                                                                        ">                         Team                     </a>                 </li>                              <li>                     <a href="research.html" class="link_nav                                                                                link_active_parent                                              ">                         Research                     </a>                 </li>                              <li>                     <a href="news.html" class="link_nav                                                                        ">                         Events                     </a>                 </li>                              <li>                     <a href="publications.html" class="link_nav                                                                        ">                         Papers                     </a>                 </li>                              <li>                     <a href="contacts.html" class="link_nav                                                                        ">                         Contacts                     </a>                 </li>                      </ul>     </div>                                             <script type="text/javascript">         function toggle() {             var nav = $('.macro_navsub693377');             nav.toggleClass('active');         }         function toggle_add() {             var nav = $('.macro_navsub693377');             if ( nav.hasClass('active') )                 nav.toggleClass('active');         }         function toggle_reg() {             var nav = $('.macro_navsub693377');             var btn = $('button.nav_toggle');             btn.on('click', function(){nav.toggleClass('active');});         }         $(document).ready(toggle_reg);         $(window).load(setTimeout(toggle_add, 3000));     </script>      <div class="macro_navsub693377 active">            <ul>             <li>                 <button class="nav_toggle"><span><</span></button>                              </li>                              <li>                     <a href="plan.html" class="link_navsub                                                                        ">                                                      Work plan                                              </a>                 </li>                              <li>                     <a href="tensor_network.html" class="link_navsub                                                                        ">                                                      Tensor networks                                              </a>                 </li>                              <li>                     <a href="neural_network.html" class="link_navsub                                                       link_active                                                                       ">                                                      Neural networks                                              </a>                 </li>                              <li>                     <a href="software.html" class="link_navsub                                                                        ">                                                      Software                                              </a>                 </li>                      </ul>     </div>           </header>                             <main class="root">   <div id='content_main' class="pages_name">         <h1>   Neural networks  </h1>  <p class="txt_long">In the past few years deep learning and deep neural networks have become one of the most popular tool for solving data mining and machine learning problems [1]. This has become possible by combination of two factors. First, large-scale (millions of annotated objects) datasets have become available [2, 3]. Second, new computational resources, such as graphic processing units, have become widely adopted [4]. Application of neural network approach has significantly improved performance of many tasks, including object classification in natural images [5] and speech-to-text conversion [6].   </p>  <p class="txt_long">The current research in deep neural networks can be broadly classified in three areas. The first one is improving the architecture of deep neural networks by increasing the number of layers [7], modifying the non linearity function [8] and introducing new layers of new types [9]. The second one is applying neural networks to the tasks that were previously solved by other methods: image segmentation [10], human pose estimation [11], depth map estimation from a single image [12]. The third one is combining several deep neural networks, each solving its particular sub-problem. Such models are then tuned by the back propagation algorithm. This direction has led to the breakthrough results in reinforcement learning [13], image caption generation [14], generation of photorealistic images [15] and machine translation [16].   </p>  <p class="txt_long">Such deep neural networks are trained on large and very large amounts of data (hundreds of thousands or millions of objects). In many applications these samples allow to configure network with hundreds of thousands and millions of parameters without the risk of retraining. However, even with the use of modern GPU, the training of these networks may take weeks or months. Moreover, even if we use learned networks for predictions (on the test data set), we have to use powerful computing resources.   </p>  <p class="txt_long">Thus, extremely high demands on computing resources significantly restrict the ability or even make it impossible to use the complex deep neural networks on personal workstations and mobile devices, as well as introduce restrictions on the complexity (size) of network architecture. These limitations inherent in modern deep neural networks, necessitate the development of new fast learning algorithms and the application of special data formats for storing the parameters of such networks.   </p>   <p class="txt_long">On the other hand, current advances in neural networks, that are described above, in the most cases are associated with heuristic construction of network architecture and applicable only to a particular problem. There is no understanding of the internal laws of working of network, of the necessity or redundancy of certain layers, of the optimal methods to choose hyperparameters, etc. The lack of comprehensive scientific answers to above questions essentially limits the qualitative development of the neural networks method.   </p>  <p class="txt_long">Currently the deep learning paradigm is on the beginning stage of its development and it poses several important problems to the researchers, related to the developing and improving the existing architectures, developments of new approaches to learning and regularizing neural networks etc. Currently the main achievements in this area are mostly related to creation of new (heuristic) architectures, and the process of development neural networks architectures for a particular applied problems is kind of an art. On the other hand, each year the hardware requirements of artificial neural networks are growing. Thus, the theoretical part of the proposed research project is related to the development of new algorithms for optimal choice of the network architecture and efficient learning and compact representation of the networks.   </p>  <p class="txt_long">It is well known that the state-of-the-art neural networks are highly redundant and contain tens of millions of parameters, using up all available memory of personal computers. However, attempts to decrease the width and depth of the neural network layers lead to a noticeable drop of the performance. To solve this problem, we plan to use the methods of tensor networks that allow constructing a compact representation of neural networks parameters to accelerate the learning process and operation of the network.   </p>The basis of the tensor networks methods is the idea of low-rank (compressed) representation of large amounts of data [1, 2], providing with compact data storage in memory and quick implementation of the basic algebra operations. During the study, we will examine the existing methods of low-rank tensor approximations and will formulate new fast algorithms for constructing such approximations.В основе методов тензорных сетей лежит идея малорангового (сжатого) представления больших объемов данных [1, 2], позволяющего компактно хранить данные в памяти и быстро осуществлять основные операции алгебры с ними. При выполнении исследования нами будут рассмотрены существующие методы малоранговых тензорных аппроксимаций и сформулированы новые быстрые алгоритмы для построения подобных аппроксимаций.   We will also find connections between the tensor and neural networks that will allow to use a rich set of methods from the theory of tensor networks for deep neural networks and to design the architecture of the deep neural networks more efficiently. Deep Neural Networks from a mathematical point of view are the methods of representation of multidimensional arrays, which are proven to be effective. A key feature of our project is that we do not limit ourselves to only one class of representations of functions, and are planning to combine it with other effective ideas. One of our main approaches is to use the formalism of tensor networks. Tensor networks are one of the most successful tools in quantum information theory, and are a way of presenting of multi-dimensional arrays with a small number of parameters. Not so long ago special (but very effective) cases of tensor networks (tensor train, hierarchical Tucker decomposition) has become fairly widespread in numerical methods and linear algebra as effective ways to approach sufficiently smooth functions of several variables.Нами будет выявлена связь между тензорными и нейронными сетями, что позволит использовать богатый набор методов из теории тензорных сетей для глубинных нейронных сетей, а также более эффективно планировать их архитектуру. Глубинные нейронные сети с математической точки зрения – это методы представления многомерных массивов, которые доказали свою эффективность. Ключевой особенностью нашего проекта является то, что мы не ограничиваемся только одним классом представления функций, а планируем объединить его с другими эффективными представлениями. Одним из основных подходов будет использование формализма тензорных сетей (tensor networks). Тензорные сети являются одним из успешных инструментов в квантовой теории информации и представляют собой способ малопараметрического представления многомерных массивов. Не так давно частные (но крайне эффективные) случаи тензорных сетей (тензорные поезда, иерархическое разложение Таккера) получили достаточное распространение в численных методах и линейной алгебре как эффективные способы приближения достаточно гладких функций многих переменных.  Functions of several variables after discretization becomes multidimensional arrays (tensors). Similar to classical matrix factorizations is possible to introduce the problem of the tensor factorizations and tensor networks provide a common approach to the representation of such factorizations. By factorization in this case it refers to the overall representation of the specified array by fewer number of parameters. Such an idea is extremely attractive to the widest range of tasks related to handling large amounts of data. Participants of the proposed study has already succeeded in applying the approach of tensor networks to signal processing applications [3], Multi-way Data Analysis and Blind Source Separation [4], brain data analysis [5], etc. A link between tensor networks and convolution neural networks remains to be seen, and the identification of such link will undoubtedly lead to new learning methods. At the end of 2015 the first attempt to establish such a link have been made in works [6, 7]. It should be noted also a number of works of Anima Anandkumar, for example, [8, 9], in which the task of learning the neural network is reduced to the tensor factorization.<br>  <h3>References</h3>  <ol class="numerated_base txt_long">   <li class="numerated_item"><p>    LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436-444.   </p></li>   <li class="numerated_item"><p>    Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., ... & Fei-Fei, L. (2014). Imagenet large scale visual recognition challenge. International Journal of Computer Vision, 1-42.   </p></li>   <li class="numerated_item"><p>    Lin, T. Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., ... & Zitnick, C. L. (2014). Microsoft COCO: Common objects in context. In Computer Vision–ECCV 2014 (pp. 740-755). Springer International Publishing.   </p></li>   <li class="numerated_item"><p>    Chetlur, S., Woolley, C., Vandermersch, P., Cohen, J., Tran, J., Catanzaro, B., & Shelhamer, E. (2014). cudnn: Efficient primitives for deep learning. arXiv preprint arXiv:1410.0759.   </p></li>   <li class="numerated_item"><p>    Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems (pp. 1097-1105).   </p></li>   <li class="numerated_item"><p>    Hinton, G., Deng, L., Yu, D., Dahl, G. E., Mohamed, A. R., Jaitly, N., ... & Kingsbury, B. (2012). Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. Signal Processing Magazine, IEEE, 29(6), 82-97.   </p></li>   <li class="numerated_item"><p>    Simonyan, K., & Zisserman, A. (2015). Very deep convolutional networks for large-scale image recognition. International Conference on Learning Representations.   </p></li>   <li class="numerated_item"><p>    He, K., Zhang, X., Ren, S., & Sun, J. (2015). Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. arXiv preprint arXiv:1502.01852.   </p></li>   <li class="numerated_item"><p>    Ioffe, S., & Szegedy, C. (2015). Batch normalization: Accelerating deep network training by reducing internal covariate shift. Proceedings of the 32nd International Conference on Machine Learning. JMLR: W&CP volume 37.   </p></li>   <li class="numerated_item"><p>    Long, J., Shelhamer, E., & Darrell, T. (2015). Fully convolutional networks for semantic segmentation. In Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference on.   </p></li>   <li class="numerated_item"><p>    Toshev, A., & Szegedy, C. (2014). Deeppose: Human pose estimation via deep neural networks. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on (pp. 1653-1660). IEEE.   </p></li>   <li class="numerated_item"><p>    Eigen, D., Puhrsch, C., & Fergus, R. (2014). Depth map prediction from a single image using a multi-scale deep network. In Advances in Neural Information Processing Systems (pp. 2366-2374).   </p></li>   <li class="numerated_item"><p>    Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., ... & Hassabis, D. (2015). Human-level control through deep reinforcement learning. Nature, 518(7540), 529-533.   </p></li>   <li class="numerated_item"><p>    Vinyals, O., Toshev, A., Bengio, S., & Erhan, D. (2015). Show and tell: A neural image caption generator. In Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference on.   </p></li>   <li class="numerated_item"><p>    Denton, E., Chintala, S., Szlam, A., & Fergus, R. (2015). Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks. In Advances in Neural Information Processing Systems.   </p></li>   <li class="numerated_item"><p>    Sutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to sequence learning with neural networks. In Advances in neural information processing systems (pp. 3104-3112).   </p></li>  </ol>       </div>  </main>        <footer class="root">  <h3 class="footer_info">   © 2017.  Tensor networks and deep learning for applications in data mining.       All rights reserved.     </h3>  <figure class="footer_links_imgs">   <a target="_blank" href="http://минобрнауки.рф/lang/en">    <img class="nopadding"  src="static//pictures/logo/min_edu.png"       width="130"      height="112">   </a>   <a target="_blank" href="http://www.skoltech.ru/en/">    <img class="nopadding"  src="static//pictures/logo/skoltech.png"      width="400"      height="147">   </a>  </figure> </footer>     </body> </html>